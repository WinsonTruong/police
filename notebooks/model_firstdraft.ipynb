{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "From the EDA, I was able to think of my dataset in terms of the officers, the suspects, and the location in which the stops happened. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# These lines make warnings look nicer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# Graphing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "import seaborn as sns\n",
    "import plotly as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqf = pd.read_csv('../data/cleaned_one_hot.csv').drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "# Changing columns names to something more comprehendible \n",
    "sqf = sqf.rename({'Other1':'Other Hair', 'Other2':'Other Hair 2',\n",
    "                'Black.1': 'Black Eyes', 'Blue':'Blue Eyes',\n",
    "                'Brown':'Brown Eyes', 'Green':'Green Eyes',\n",
    "                'Gray': 'Gray Eyes', 'Hazel': 'Hazel Eyes',\n",
    "                'Multicolor': 'Multicolor Eyes', 'Other4': 'Other Eyes 4',\n",
    "                'Other5': 'Other Eyes 5', 'Other6':'Other Eyes 6'}, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "Outcome Variable: Frisking (1/0)\n",
    "\n",
    "Feature Sets\n",
    "1. race\n",
    "2. appearance (race + physical characteristics)\n",
    "3. full context (aforementioned + environmental influences)\n",
    "\n",
    "Models\n",
    "1. Logistic Regression (Baseline)\n",
    "2. Logistic Regression with Regularization (avoiding overfitting)\n",
    "3. SVM\n",
    "\n",
    "Statistics\n",
    "1. Accuracy\n",
    "2. Precision\n",
    "3. Recall\n",
    "\n",
    "Goal: a 3x9 table that describes all combinations of the models, featuresets, and statstics (see results.xlxs)\n",
    "\n",
    "Steps\n",
    "1. Wrangle the data to create my feature sets\n",
    "2. Describe the assumptions behind each model\n",
    "3. Run the function (generalizeable thanks to sklearn)\n",
    "4. Compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_summary = pd.DataFrame(columns = ['Accuracy', 'Precision', 'Recall'], \n",
    "                       index = ['Logistic', 'Logisitic + Regularization', 'SVM'])\n",
    "appearance_summary = pd.DataFrame(columns = ['Accuracy', 'Precision', 'Recall'], \n",
    "                       index = ['Logistic', 'Logisitic + Regularization', 'SVM'])\n",
    "\n",
    "context_summary = pd.DataFrame(columns = ['Accuracy', 'Precision', 'Recall'], \n",
    "                       index = ['Logistic', 'Logisitic + Regularization', 'SVM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle\n",
    "This section will create 3 dataframes\n",
    "* race contains racial identifying features of the suspect\n",
    "* appearance contains any physical features of the suspect, including race\n",
    "* context contains all possible descriptors the environment in which the officer stopped the suspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw = sqf['frisked_flag']\n",
    "\n",
    "race = pd.concat([sqf.iloc[:, 23:29]], axis = 1)\n",
    "appearance = pd.concat([sqf.iloc[:,19:58]], axis = 1)\n",
    "\n",
    "# One-hot encoding the NY bourough for context \n",
    "borough = pd.get_dummies(sqf['stop_location_boro_name'])\n",
    "context = pd.concat([appearance, borough], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the convergence process while running models, I will now normalize these dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suspect_reported_age</th>\n",
       "      <th>suspect_height</th>\n",
       "      <th>suspect_weight</th>\n",
       "      <th>female</th>\n",
       "      <th>Indian/Alaskan Native</th>\n",
       "      <th>Asian / Pacific Islander</th>\n",
       "      <th>Black</th>\n",
       "      <th>Black Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>White Hispanic</th>\n",
       "      <th>...</th>\n",
       "      <th>Black Eyes</th>\n",
       "      <th>Blue Eyes</th>\n",
       "      <th>Brown Eyes</th>\n",
       "      <th>Green Eyes</th>\n",
       "      <th>Gray Eyes</th>\n",
       "      <th>Hazel Eyes</th>\n",
       "      <th>Multicolor Eyes</th>\n",
       "      <th>Other Eyes 4</th>\n",
       "      <th>Other Eyes 5</th>\n",
       "      <th>Other Eyes 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.149665</td>\n",
       "      <td>-1.584446</td>\n",
       "      <td>1.959845</td>\n",
       "      <td>-0.316528</td>\n",
       "      <td>-0.022893</td>\n",
       "      <td>-0.151021</td>\n",
       "      <td>0.816695</td>\n",
       "      <td>-0.302741</td>\n",
       "      <td>-0.313514</td>\n",
       "      <td>-0.505984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328827</td>\n",
       "      <td>-0.121369</td>\n",
       "      <td>0.445248</td>\n",
       "      <td>-0.082342</td>\n",
       "      <td>-0.044994</td>\n",
       "      <td>-0.08984</td>\n",
       "      <td>-0.012234</td>\n",
       "      <td>-0.019346</td>\n",
       "      <td>-0.012234</td>\n",
       "      <td>-0.193017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.522424</td>\n",
       "      <td>-1.584446</td>\n",
       "      <td>0.728874</td>\n",
       "      <td>-0.316528</td>\n",
       "      <td>-0.022893</td>\n",
       "      <td>-0.151021</td>\n",
       "      <td>0.816695</td>\n",
       "      <td>-0.302741</td>\n",
       "      <td>-0.313514</td>\n",
       "      <td>-0.505984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328827</td>\n",
       "      <td>-0.121369</td>\n",
       "      <td>0.445248</td>\n",
       "      <td>-0.082342</td>\n",
       "      <td>-0.044994</td>\n",
       "      <td>-0.08984</td>\n",
       "      <td>-0.012234</td>\n",
       "      <td>-0.019346</td>\n",
       "      <td>-0.012234</td>\n",
       "      <td>-0.193017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.333951</td>\n",
       "      <td>0.583581</td>\n",
       "      <td>2.575330</td>\n",
       "      <td>-0.316528</td>\n",
       "      <td>-0.022893</td>\n",
       "      <td>-0.151021</td>\n",
       "      <td>-1.224355</td>\n",
       "      <td>-0.302741</td>\n",
       "      <td>3.189407</td>\n",
       "      <td>-0.505984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328827</td>\n",
       "      <td>8.238711</td>\n",
       "      <td>-2.245772</td>\n",
       "      <td>-0.082342</td>\n",
       "      <td>-0.044994</td>\n",
       "      <td>-0.08984</td>\n",
       "      <td>-0.012234</td>\n",
       "      <td>-0.019346</td>\n",
       "      <td>-0.012234</td>\n",
       "      <td>-0.193017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.606435</td>\n",
       "      <td>0.583581</td>\n",
       "      <td>-0.502098</td>\n",
       "      <td>-0.316528</td>\n",
       "      <td>-0.022893</td>\n",
       "      <td>-0.151021</td>\n",
       "      <td>0.816695</td>\n",
       "      <td>-0.302741</td>\n",
       "      <td>-0.313514</td>\n",
       "      <td>-0.505984</td>\n",
       "      <td>...</td>\n",
       "      <td>3.040889</td>\n",
       "      <td>-0.121369</td>\n",
       "      <td>-2.245772</td>\n",
       "      <td>-0.082342</td>\n",
       "      <td>-0.044994</td>\n",
       "      <td>-0.08984</td>\n",
       "      <td>-0.012234</td>\n",
       "      <td>-0.019346</td>\n",
       "      <td>-0.012234</td>\n",
       "      <td>-0.193017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.942479</td>\n",
       "      <td>0.583581</td>\n",
       "      <td>-0.502098</td>\n",
       "      <td>-0.316528</td>\n",
       "      <td>-0.022893</td>\n",
       "      <td>-0.151021</td>\n",
       "      <td>0.816695</td>\n",
       "      <td>-0.302741</td>\n",
       "      <td>-0.313514</td>\n",
       "      <td>-0.505984</td>\n",
       "      <td>...</td>\n",
       "      <td>3.040889</td>\n",
       "      <td>-0.121369</td>\n",
       "      <td>-2.245772</td>\n",
       "      <td>-0.082342</td>\n",
       "      <td>-0.044994</td>\n",
       "      <td>-0.08984</td>\n",
       "      <td>-0.012234</td>\n",
       "      <td>-0.019346</td>\n",
       "      <td>-0.012234</td>\n",
       "      <td>-0.193017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   suspect_reported_age  suspect_height  suspect_weight    female  \\\n",
       "0              0.149665       -1.584446        1.959845 -0.316528   \n",
       "1             -0.522424       -1.584446        0.728874 -0.316528   \n",
       "2              2.333951        0.583581        2.575330 -0.316528   \n",
       "3             -0.606435        0.583581       -0.502098 -0.316528   \n",
       "4             -0.942479        0.583581       -0.502098 -0.316528   \n",
       "\n",
       "   Indian/Alaskan Native  Asian / Pacific Islander     Black  Black Hispanic  \\\n",
       "0              -0.022893                 -0.151021  0.816695       -0.302741   \n",
       "1              -0.022893                 -0.151021  0.816695       -0.302741   \n",
       "2              -0.022893                 -0.151021 -1.224355       -0.302741   \n",
       "3              -0.022893                 -0.151021  0.816695       -0.302741   \n",
       "4              -0.022893                 -0.151021  0.816695       -0.302741   \n",
       "\n",
       "      White  White Hispanic  ...  Black Eyes  Blue Eyes  Brown Eyes  \\\n",
       "0 -0.313514       -0.505984  ...   -0.328827  -0.121369    0.445248   \n",
       "1 -0.313514       -0.505984  ...   -0.328827  -0.121369    0.445248   \n",
       "2  3.189407       -0.505984  ...   -0.328827   8.238711   -2.245772   \n",
       "3 -0.313514       -0.505984  ...    3.040889  -0.121369   -2.245772   \n",
       "4 -0.313514       -0.505984  ...    3.040889  -0.121369   -2.245772   \n",
       "\n",
       "   Green Eyes  Gray Eyes  Hazel Eyes  Multicolor Eyes  Other Eyes 4  \\\n",
       "0   -0.082342  -0.044994    -0.08984        -0.012234     -0.019346   \n",
       "1   -0.082342  -0.044994    -0.08984        -0.012234     -0.019346   \n",
       "2   -0.082342  -0.044994    -0.08984        -0.012234     -0.019346   \n",
       "3   -0.082342  -0.044994    -0.08984        -0.012234     -0.019346   \n",
       "4   -0.082342  -0.044994    -0.08984        -0.012234     -0.019346   \n",
       "\n",
       "   Other Eyes 5  Other Eyes 6  \n",
       "0     -0.012234     -0.193017  \n",
       "1     -0.012234     -0.193017  \n",
       "2     -0.012234     -0.193017  \n",
       "3     -0.012234     -0.193017  \n",
       "4     -0.012234     -0.193017  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize(df):\n",
    "    \"\"\"\n",
    "    A quick, and simple standardization function that relies just on pandas\n",
    "    Input: dataframe\n",
    "    Output: dataframe, standardized\n",
    "    \"\"\"\n",
    "    return (df-df.mean())/df.std()\n",
    "\n",
    "race = standardize(race)\n",
    "appearance = standardize(appearance)\n",
    "context = standardize(appearance)\n",
    "\n",
    "context.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great let's begin modeling \n",
    "## Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLM\n",
    "np.random.seed(7132013)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def logistic_reg(df):\n",
    "    \"\"\"\n",
    "    Create a logistic regression classifier of a dataframe\n",
    "    Input: the feature matrix, which includes the output variable in the first column\n",
    "    Output: the accuracy, precision, and recall of the matrix\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    X = df\n",
    "    y = y_raw\n",
    "    \n",
    "    # 80/20 Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "    \n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    \n",
    "    accuracy = log_reg.score(X_test, y_test)\n",
    "    precision = classification_report(y_test, y_pred, output_dict = True)['weighted avg']['precision']\n",
    "    recall = classification_report(y_test, y_pred, output_dict = True)['weighted avg']['recall']\n",
    "    \n",
    "    return [accuracy, precision, recall]\n",
    "\n",
    "race_summary.iloc[0,:] = logistic_reg(race)\n",
    "appearance_summary.iloc[0,:] = logistic_reg(appearance)\n",
    "context_summary.iloc[0,:] = logistic_reg(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.565221</td>\n",
       "      <td>0.580247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logisitic + Regularization</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy Precision    Recall\n",
       "Logistic                    0.580247  0.565221  0.580247\n",
       "Logisitic + Regularization       NaN       NaN       NaN\n",
       "SVM                              NaN       NaN       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.594089</td>\n",
       "      <td>0.600498</td>\n",
       "      <td>0.594089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logisitic + Regularization</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy Precision    Recall\n",
       "Logistic                    0.594089  0.600498  0.594089\n",
       "Logisitic + Regularization       NaN       NaN       NaN\n",
       "SVM                              NaN       NaN       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.608305</td>\n",
       "      <td>0.61157</td>\n",
       "      <td>0.608305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logisitic + Regularization</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy Precision    Recall\n",
       "Logistic                    0.608305   0.61157  0.608305\n",
       "Logisitic + Regularization       NaN       NaN       NaN\n",
       "SVM                              NaN       NaN       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(race_summary,appearance_summary, context_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "What does precision mean in this context? Keep in mind that we are thinking of our machine as a model for an officer in which they are determining if they should frisk a suspect based off their physical appearance. The precision of 0.61 means that of all frisked individuals, our appearance model was able to correctly predict if someone would be frisked based on how they look about 60% of the time. In terms of real-world behavior, this shows that officers are looking at more than just appearance - perhaps they are using their unconscious bias.\n",
    "\n",
    "Overall this leads to a greater discussion about the **fairness of policing**. From a data science and decision theory perspective, we can _consider_ fair policing to mean the following:\n",
    "\n",
    "* each race is equally likely to be frisked (equal positve rates)\n",
    "* each race is equally likely to not be frisked (equal error rates)\n",
    "* each race is equally likely to be frisked on reasonable suspicion, but then no other consequences, say arrest, occurs (equal false positive rates)\n",
    "\n",
    "**However**, policing is not about being fair across races as much as it is meant to keep peace, enforce the laws, and uphold justice. SQF is not fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2673, 1337]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-ee82ce79e7ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0msupport_VM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-ee82ce79e7ca>\u001b[0m in \u001b[0;36msupport_VM\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weighted avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weighted avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1927\u001b[0m     \"\"\"\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 257\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2673, 1337]"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "def support_VM(df):\n",
    "    \"\"\"\n",
    "    Create a  classifier of a dataframe\n",
    "    Input: the feature matrix, which includes the output variable in the first column\n",
    "    Output: the accuracy, precision, and recall of the matrix\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    X = df\n",
    "    y = y_raw\n",
    "    \n",
    "    # 80/20 Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "    \n",
    "\n",
    "    svc = SVC(kernel='linear')\n",
    "    svc.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = svc.score(X_test, y_test)\n",
    "    precision = classification_report(y_test, y_pred, output_dict = True)['weighted avg']['precision']\n",
    "    recall = classification_report(y_test, y_pred, output_dict = True)['weighted avg']['recall']\n",
    "    \n",
    "    return [accuracy, precision, recall]\n",
    "\n",
    "support_VM(race)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import roc_curve\n",
    "# log_reg_roc_auc = roc_auc_score(y_test, log_reg.predict(X_test))\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, log_reg.predict_proba(X_test)[:,1])\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % log_reg_roc_auc)\n",
    "# plt.plot([0, 1], [0, 1],'r--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.savefig('Log_ROC')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
